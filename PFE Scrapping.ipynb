{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc51dfc3",
   "metadata": {},
   "source": [
    "# PFE : Analyse de données statistiques sportives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bf79cb",
   "metadata": {},
   "source": [
    "## I. Scrapping des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2977d93",
   "metadata": {},
   "source": [
    "Dans un premier temps, nous allons chercher à prédire le prochain MVP en NBA.\n",
    "Pour cela, on s'intéressera aux informations suivantes :\n",
    "- Votes MVP de chaque année depuis 1980 \n",
    "- Statistiques des joueurs depuis 1980\n",
    "- Statistiques des équipes depuis 1980  \n",
    "\n",
    "Remarque : On récupère les données depuis 1980 car la saison 1980-1981 était la première saison pour laquelle ce n'était plus les joueurs qui votaient mais des journalistes et des commentateurs comme c'est le cas actuellement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b6660e",
   "metadata": {},
   "source": [
    "### Basketball Reference\n",
    "Nous récupérons les données (dans un premier temps) sur le site https://www.basketball-reference.com qui répertorie un nombre conséquent de statistiques en NBA pour chaque saison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73bacd",
   "metadata": {},
   "source": [
    "On commence tout d'abord par repérer les pages qui vont nous intéresser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c48d7b7",
   "metadata": {},
   "source": [
    "### Votes MVP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259a51a8",
   "metadata": {},
   "source": [
    "<img src=\"image/img1.png\" style=\"height:300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176e460e",
   "metadata": {},
   "source": [
    "Sur cette page, on a les votes du MVP pour la saison 2021-2022 ainsi il faudrait être capable de récupérer la page correspondante pour chaque saison depuis 1980.\n",
    "Ce qui nous fait une quarantaine de page à récupérer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0efd2c",
   "metadata": {},
   "source": [
    "### Statistiques joueurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25152d22",
   "metadata": {},
   "source": [
    "<img src=\"image/img2.png\" style=\"height:300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea0b706",
   "metadata": {},
   "source": [
    "Sur cette page, on a les statistiques moyennes par match pour chaque joueur pour la saison 2021-2022 ainsi il faudrait être capable de récupérer la page correspondante pour chaque saison depuis 1980. Ce qui nous fait une quarantaine de page à récupérer.\n",
    "\n",
    "Remarque : Certains joueurs apparaissent en double voire triple car ces statistiques sont calculés pour chaque équipe\n",
    "dans lesquelles ils ont joué durant la saison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaaf4b3",
   "metadata": {},
   "source": [
    "### Statistiques des équipes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3d7242",
   "metadata": {},
   "source": [
    "<img src=\"image/img3.png\" style=\"height:300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75435f3c",
   "metadata": {},
   "source": [
    "Sur cette page, nous avons les statistiques des équipes de la conférence Est de la NBA ainsi que celles de la conférence Ouest.\n",
    "On va chercher à récupérer une combinaison de ces deux tableaux pour chaque année depuis 1980. Ce qui nous fait une quarantaine de page à récupérer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd316d",
   "metadata": {},
   "source": [
    "### BILAN\n",
    "On a donc environ 120 pages à récupérer, il va donc nous falloir 120 requêtes.\n",
    "\n",
    "### PROBLEME\n",
    "\n",
    "Le site Basketball Reference possède une protection contre les attaques DDOS ce qui provoque un ban ip au bout d'une trantaine de requêtes consécutives, ce qui pose problème dans notre cas.\n",
    "\n",
    "On a donc trouvé une solution en nous tournant vers le module Selenium qui de part son fonctionnement, contourne cette protection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893cfbfb",
   "metadata": {},
   "source": [
    "## CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c041ef4",
   "metadata": {},
   "source": [
    "### Import des librairies nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40e1d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f511b87",
   "metadata": {},
   "source": [
    "### Définition de variable générale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd7647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "years =  list(range(1980,2022)) #liste des années dont on récupère les données\n",
    "s = Service('/chromedriver/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = s) #définition du driver chrome pour le scrapping avec selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57d2c1e",
   "metadata": {},
   "source": [
    "### A) Scrapping votes MVP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82a6e23",
   "metadata": {},
   "source": [
    "1) Récupération des fichiers html associés à chaque page contenant les votes MVP que l'on stocke dans un dossier \"mvp\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51580019",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_mvps = \"https://www.basketball-reference.com/awards/awards_{}.html\"\n",
    "for year in years:\n",
    "    url = url_mvps.format(year)\n",
    "    driver.get(url)\n",
    "    html = driver.page_source #grab the data\n",
    "    with open(\"mvp/{}.html\".format(year),\"w+\",encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229afcda",
   "metadata": {},
   "source": [
    "2) Exploitation des fichiers html pour créer un dataframe exploitable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f94d01",
   "metadata": {},
   "source": [
    "En s'intéressant au fichier html, en repère rapidement la partie du code qui va nous intéresser (ici la balise ayant pour id  \"mvp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf0130e",
   "metadata": {},
   "source": [
    "<img src=\"image/img4.png\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4a38ba",
   "metadata": {},
   "source": [
    "On en profite pour retirer directement la ligne \"over_header\" qui n'a pas d'utilité dans notre étude "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1dc2c1",
   "metadata": {},
   "source": [
    "<img src=\"image/img5.png\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecbdb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for year in years:\n",
    "    with open(\"mvp/{}.html\".format(year),encoding=\"utf-8\") as f:\n",
    "        page = f.read()\n",
    "    soup = BeautifulSoup(page,\"html.parser\")\n",
    "    if(soup.find('tr',class_ = \"over_header\")!=None):\n",
    "        soup.find('tr',class_ = \"over_header\").decompose()\n",
    "    \n",
    "    mvp_table = soup.find_all(id = \"mvp\")\n",
    "    mvp = pd.read_html(str(mvp_table))[0]\n",
    "    mvp[\"Year\"] = year #Pour distinguer l'année dont vient les données\n",
    "    dfs.append(mvp)\n",
    "mvps = pd.concat(dfs)\n",
    "mvps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16936fdd",
   "metadata": {},
   "source": [
    "3) Envoi dans un base de donnée SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35cb1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvpcon = sqlite3.connect('mvp.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b389d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvps.to_sql(\"MVP\", con = mvpcon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5664da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mvpcon.execute(\"SELECT * FROM MVP\").fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43320857",
   "metadata": {},
   "source": [
    "### B)  Scrapping statistiques joueurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f51592",
   "metadata": {},
   "source": [
    "1) Récupération des fichiers html associés à chaque page contenant les statistiques des joueurs que l'on stocke dans un dossier \"player\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b1d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_stats_url = \"https://www.basketball-reference.com/leagues/NBA_{}_per_game.html\"\n",
    "for year in years:\n",
    "    url = player_stats_url.format(year)\n",
    "    driver.get(url)\n",
    "    html = driver.page_source #grab the data\n",
    "    with open(\"player/{}.html\".format(year),\"w+\",encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10da2798",
   "metadata": {},
   "source": [
    "2) Exploitation des fichiers html pour créer un dataframe exploitable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a27b65a",
   "metadata": {},
   "source": [
    "En s'intéressant au fichier html, en repère rapidement la partie du code qui va nous intéresser (ici la balise ayant pour id  \"per_game_stats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef417e28",
   "metadata": {},
   "source": [
    "<img src=\"image/img8.png\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee28d241",
   "metadata": {},
   "source": [
    "On en profite pour retirer les \"thead\" qui ne sont pas utiles pour notre étude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a544fc3b",
   "metadata": {},
   "source": [
    "<img src=\"image/img9.png\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6262aa26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs2 = []\n",
    "for year in years:\n",
    "    with open(\"player/{}.html\".format(year),encoding=\"utf-8\") as f:\n",
    "        page = f.read()\n",
    "    soup = BeautifulSoup(page,\"html.parser\")\n",
    "    tHeads = soup.findAll('tr', class_=\"thead\")\n",
    "    for tHead in tHeads:\n",
    "        tHead.decompose()\n",
    "    player_table = soup.find(id = \"per_game_stats\")\n",
    "    player = pd.read_html(str(player_table))[0]\n",
    "    player[\"Year\"] = year\n",
    "    dfs2.append(player)\n",
    "players = pd.concat(dfs2)\n",
    "players"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3646f2",
   "metadata": {},
   "source": [
    "3) Envoi dans un base de donnée SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "playerscon = sqlite3.connect('players.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1059320",
   "metadata": {},
   "outputs": [],
   "source": [
    "players.to_sql(\"PLAYERS\", con = playerscon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966f49d6",
   "metadata": {},
   "source": [
    "### C) Scrapping des statistiques des équipes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06dd880",
   "metadata": {},
   "source": [
    "1) Récupération des fichiers html associés à chaque page contenant les statistiques des équipes que l'on stocke dans un dossier \"team\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58275dcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_stats_url = \"https://www.basketball-reference.com/leagues/NBA_{}_standings.html\"\n",
    "for year in years:\n",
    "    url = team_stats_url.format(year)\n",
    "    driver.get(url)\n",
    "    html = driver.page_source #grab the data\n",
    "    with open(\"team/{}.html\".format(year),\"w+\",encoding=\"utf-8\") as f:\n",
    "        f.write(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacc9a28",
   "metadata": {},
   "source": [
    "2) Exploitation des fichiers html pour créer un dataframe exploitable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de66f31",
   "metadata": {},
   "source": [
    "En s'intéressant au fichier html, en repère rapidement la partie du code qui va nous intéresser. Ici ce sont les balises ayant pour id  \"divs_standings_E\" et \"divs_standings_W\" qui représentent respectivement les statistiques des équipes de la conférence Est de la Nba et celle de l'Ouest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf39aee5",
   "metadata": {},
   "source": [
    "Conférence Est\n",
    "<img src=\"image/img10.png\" style=\"height:350px\">\n",
    "Conférence Ouest\n",
    "<img src=\"image/img11.png\" style=\"height:350px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9e256c",
   "metadata": {},
   "source": [
    "On en profite pour retirer encore une fois les \"thead\" inutiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6ad2c2",
   "metadata": {},
   "source": [
    "<img src=\"image/img12.png\" style=\"height:300px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae309a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs3 = []\n",
    "for year in years: \n",
    "    \n",
    "    with open(\"team/{}.html\".format(year),encoding=\"utf-8\") as f:\n",
    "        page = f.read()\n",
    "    soup = BeautifulSoup(page,\"html.parser\")\n",
    "    if(soup.find('tr', class_=\"thead\")!=None):\n",
    "         soup.find('tr', class_=\"thead\").decompose()\n",
    "    team_table = soup.find(id = \"divs_standings_E\")\n",
    "    team = pd.read_html(str(team_table))[0]\n",
    "    team[\"Year\"] = year\n",
    "    team[\"Team\"] = team[\"Eastern Conference\"]\n",
    "    del team[\"Eastern Conference\"]\n",
    "    dfs3.append(team)\n",
    "\n",
    "    soup = BeautifulSoup(page,\"html.parser\")\n",
    "    if(soup.find('tr', class_=\"thead\")!=None):\n",
    "        \n",
    "        soup.find('tr', class_=\"thead\").decompose()\n",
    "   \n",
    "    team_table = soup.find(id = \"divs_standings_W\")\n",
    "    team = pd.read_html(str(team_table))[0]\n",
    "    team[\"Year\"] = year\n",
    "    team[\"Team\"] = team[\"Western Conference\"]\n",
    "    del team[\"Western Conference\"]\n",
    "    dfs3.append(team)\n",
    "teams = pd.concat(dfs3)\n",
    "teams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e83468c",
   "metadata": {},
   "source": [
    "3) Envoi dans un base de donnée SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da161b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "teamscon = sqlite3.connect('teams.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d4f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams.to_sql(\"TEAMS\", con = teamscon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
